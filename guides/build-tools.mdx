---
title: "Build & List Your Tool"
description: "Step-by-step guide to building an MCP server and listing it on the Context marketplace"
---

<Info>
**New to MCP?** Start with our [5-Minute Quickstart](/guides/quickstart) to build and deploy your first server, then come back here for advanced features.
</Info>

<Info>
**Running on hobby/free API tiers?** Publish `_meta.rateLimit` hints on your tools so planner + runtime can pace safely. See [Rate-Limit Metadata](/guides/rate-limit-metadata).
</Info>

## Overview

Want to earn revenue from your data? **Turn the insights people pay \$500/year for into \$0.10/response revenue you keep.** Build an MCP server and register it as an **MCP Tool** on the Context marketplace.

---

## AI-Assisted Builder (TL;DR)

**Have an API subscription you want to unbundle?** Use Cursor, Claude, or any AI coding agent to build your MCP server automatically.

<Warning>
**Prerequisite**: You need [Context7 MCP](https://github.com/upstash/context7) configured in your AI coding environment to fetch API documentation automatically.
</Warning>

### Two-Step Workflow

<Steps>
  <Step title="Build the MCP Server">
    Use the **[MCP Builder Template](https://github.com/ctxprotocol/sdk/blob/main/docs/mcp-builder-template.md)** as a system prompt to:
    - Fetch API docs via Context7 and discover all endpoints
    - Design "giga-brained" intelligence tools (not just API passthroughs)
    - Generate complete schemas with `outputSchema`
    - Implement the full MCP server
    
    ```
    Use the mcp-builder-template.md with Context7 for [your-api-library-id].
    Fetch the documentation and design tools that answer complex questions.
    ```
  </Step>
  
  <Step title="Generate Submission Details">
    Once your server is built, use the **[MCP Server Analysis Prompt](https://github.com/ctxprotocol/sdk/blob/main/docs/mcp-server-analysis-prompt.md)** to:
    - Analyze your MCP server implementation
    - Generate the perfect submission details for the marketplace form
    - Get suggested name, description, category, and pricing
    
    ```
    Paste the mcp-server-analysis-prompt.md into your AI chat, then provide your server.ts code or repository URL.
    ```
  </Step>
</Steps>

### Example Prompt for Cursor/Claude

```
I want to build an MCP server for the Context Marketplace using the CoinGecko API.

1. Use context7 to fetch the CoinGecko API documentation
2. Follow the mcp-builder-template.md workflow:
   - PHASE 1: Discover all endpoints
   - PHASE 2: Generate discovery questions (STOP for my review)
   - PHASE 3: Design and implement tools after I approve

Focus on "giga-brained" tools that combine multiple endpoints to answer
questions users couldn't easily answer with raw API calls.
```

<Tip>
The builder template includes checkpoints where the AI will stop and ask for your approval before proceeding. This ensures you get tools that match your vision.
</Tip>

---

<Info>
**Earnings Model**: You earn **90%** of every response fee. Set your price (e.g., \$0.01/response) and get paid in USDC on Base every time an Agent successfully uses your tool. Payment is settled automatically after execution.
</Info>

---

## Step 1: Build a Standard MCP Server

Use the official `@modelcontextprotocol/sdk` to build your server, plus `@ctxprotocol/sdk` to secure your endpoint.

### Install Dependencies

```bash
pnpm add @modelcontextprotocol/sdk express
pnpm add @ctxprotocol/sdk
pnpm add -D @types/express
```

### Implement Structured Output

<Warning>
**Required for Context**: You must implement the MCP structured output standard:
- `outputSchema` in your tool definitions (JSON Schema describing your response structure)
- `structuredContent` in your responses (the machine-readable data matching your schema)
</Warning>

```typescript
// MCP spec compliant server (see: modelcontextprotocol.io/specification)
const TOOLS = [{
  name: "get_gas_price",
  description: "Get current gas prices for any EVM chain",
  inputSchema: {
    type: "object",
    properties: {
      chainId: { type: "number", description: "EVM chain ID" },
    },
  },
  outputSchema: {  // ğŸ‘ˆ Required by Context
    type: "object",
    properties: {
      gasPrice: { type: "number" },
      unit: { type: "string" },
    },
    required: ["gasPrice", "unit"],
  },
}];

// In your tool handler
return {
  content: [{ type: "text", text: JSON.stringify(data) }],  // Backward compat
  structuredContent: data,  // ğŸ‘ˆ Required by Context
};
```

### Design Outputs for Context Windows

Contextâ€™s query pipeline uses model-aware data budgets when preparing tool output for synthesis. To maximize answer quality:

<Info>
**Best practices for `structuredContent`:**

- Return **structured objects** (not one giant serialized string blob)
- Keep **textual analysis/news** in dedicated string fields (these are prioritized first)
- Keep **large time-series arrays** in separate keys from analysis text
- Include a compact `summary` object alongside deep raw data when possible
- Aim for payloads under **~500K chars** for full visibility across all supported models
</Info>

```typescript
// âœ… Good: separated and prioritizable
return {
  summary: { direction: "outflow", confidence: 0.82 },
  news: "ETF outflows accelerated this week due to ...",
  chart: { timestamps: [...], values: [...] },
};

// âŒ Bad: giant opaque blob (hard to prioritize/truncate safely)
return JSON.stringify(allData);
```

### Write Detailed Output Schemas (Critical for Performance)

Your `outputSchema` is the **single most impactful thing** you can do to reduce latency and cost for users. Here's why:

Context's agentic pipeline uses a **planning LLM** that reads your `outputSchema` to generate code that processes your tool's response. If your schema is vague, the LLM has to *guess* property names â€” and it will guess wrong. This triggers an automatic **self-healing retry loop** that:

- Adds **~30-60 seconds** of latency per retry
- Costs **~$0.02 extra** in model inference per retry
- Wastes retry budget (capped at 8 total iterations)

The #1 cause of these retries? **Property name mismatches** between what the LLM generates and what your tool actually returns.

<Note>
Self-healing retries target likely code/data-shape issues. Infrastructure failures (rate limits, auth failures, upstream timeouts) are treated as non-healable for that turn, so the platform does not keep rewriting code when the root cause is upstream.
</Note>

<Note>
If your tool explicitly reports plan/tier capability limits (for example, "long/short ratio unavailable on current tier"), the platform treats that as a constraint signal and avoids repeated same-tool completeness rewrites. It will return best-effort output plus limitations instead of looping.
</Note>

<Tip>
Expose capability flags in `structuredContent` (for example, `supportsLongShortThresholdCheck: false`) and include a human-readable `limitations` field. This helps the verifier distinguish true parsing bugs from plan constraints.
</Tip>

<Tip>
For third-party APIs with strict quotas, publish pacing hints in tool metadata so the planner and runtime can coordinate:

```typescript
const TOOLS = [{
  name: "get_portfolio_snapshot",
  description: "Fetch portfolio snapshot",
  _meta: {
    rateLimit: {
      maxRequestsPerMinute: 30,
      cooldownMs: 2000,
      maxConcurrency: 1,
      supportsBulk: true,
      recommendedBatchTools: ["get_portfolio_snapshot"],
      notes: "Hobby tier: avoid per-asset fan-out loops.",
    },
  },
  inputSchema: { /* ... */ },
  outputSchema: { /* ... */ },
}];
```

These hints are advisory for planning and also consumed by runtime pacing logic.

Reference implementation: [Coinglass contributor server](https://github.com/ctxprotocol/sdk/tree/main/examples/server/coinglass-contributor).
</Tip>

<Warning>
**The planning LLM defaults to camelCase** (standard JavaScript convention). If your API returns `snake_case` and your `outputSchema` doesn't document the exact property names, the LLM will generate `data.exchangeName` when your API returns `data.exchange_name` â€” triggering a retry every time.
</Warning>

```typescript
// âŒ Bad: Vague schema â€” LLM must guess property names
outputSchema: {
  type: "object",
  properties: {
    data: { type: "array" }  // What's in the array? LLM will guess wrong.
  }
}

// âœ… Good: Detailed schema with exact property names and descriptions
outputSchema: {
  type: "object",
  properties: {
    data: {
      type: "array",
      description: "Array of exchange balance objects, one per exchange",
      items: {
        type: "object",
        properties: {
          exchange_name: { type: "string", description: "Exchange name (e.g. 'Binance')" },
          total_balance: { type: "number", description: "Total balance in the queried coin" },
          balance_change_1d: { type: "number", description: "Balance change in last 24 hours" },
          balance_change_percent_1d: { type: "number", description: "Percent change in last 24 hours" },
        }
      }
    },
    fetchedAt: { type: "string", description: "ISO 8601 timestamp" }
  }
}
```

<Info>
**Output schema checklist:**

- Document **every property name** in the response, especially if they're `snake_case`
- Include **`items.properties`** for arrays â€” don't just say `{ type: "array" }`
- Add **descriptions** that explain what values mean (units, ranges, interpretation)
- If the response is an **object** (not an array), say so â€” `{ type: "object" }` not `{ type: "array" }`
- Document **wrapper properties** your handler adds (e.g., `fetchedAt`, `count`, `symbol`)
</Info>

### Secure Your Endpoint

Add Context's middleware to verify that requests are legitimate:

```typescript
import express from "express";
import { createContextMiddleware } from "@ctxprotocol/sdk";

const app = express();
app.use(express.json());

// 1 line of code to secure your endpoint & handle payments
app.use("/mcp", createContextMiddleware());

// ...

// Why this middleware matters:
// 1. Verifies that requests are signed by the Context Platform (preventing free-riding)
// 2. Injects user context (if requested)
// 3. Handles payment verification automatically
```

### Returning Images from Tools

If your tool generates charts, heatmaps, screenshots, or other visual content, **you are responsible for hosting the images** and returning URLs that the AI can reference.

<Warning>
**Do not return base64-encoded images** in your tool responses. Large base64 strings bloat the response, slow down processing, and may hit token limits. Instead, host your images and return URLs.
</Warning>

#### Recommended: Return Image URLs

```typescript
return {
  content: [
    { type: "text", text: "Analysis complete. Here's the chart:" }
  ],
  structuredContent: {
    summary: "Market analysis shows bullish signals...",
    // Host your images and return URLs
    chart_url: "https://your-cdn.com/charts/eth-analysis-12345.png",
    chart_alt: "ETH price chart with support levels marked"
  }
};
```

#### Why You Should Host Images

1. **No database bloat** â€” URLs are small strings; base64 images are 100x larger
2. **Faster responses** â€” No large payloads to transfer
3. **Standard web pattern** â€” This is how Slack, Discord, and every major chat platform works
4. **You control caching** â€” Set your own CDN caching policies
5. **You control availability** â€” Your images, your infrastructure, your reliability

#### Image Hosting Options

| Option | Best For |
|--------|----------|
| **Your existing CDN** | If you already have infrastructure |
| **Cloud storage** (S3, GCS, Azure Blob) | Pre-signed URLs for generated content |
| **Vercel Blob / Cloudflare R2** | Simple, cheap storage for generated images |
| **Imgix / Cloudinary** | Image transformation and optimization |

#### Output Schema for Image Tools

```json
{
  "type": "object",
  "properties": {
    "summary": {
      "type": "string",
      "description": "Text summary of the analysis"
    },
    "chart_url": {
      "type": "string",
      "format": "uri",
      "description": "URL to the hosted chart image"
    },
    "chart_alt": {
      "type": "string",
      "description": "Accessible description of the image"
    }
  },
  "required": ["summary", "chart_url"]
}
```

<Tip>
The AI will include your image URL in its response, and users can click to view. For the best experience, use publicly accessible URLs (no auth required) with reasonable cache headers.
</Tip>

<Info>
**Free vs Paid Security Requirements:**

| Tool Type | Security Middleware | Rationale |
|-----------|---------------------|-----------|
| **Free Tools ($0.00)** | **Optional** | Great for distribution and adoption â€” anyone can call your endpoint |
| **Paid Tools ($0.01+)** | **Mandatory** | We cannot route payments to insecure endpoints |

If you're building a free tool, you can skip the middleware entirely. However, if you ever want to charge for your tool, you'll need to add it.
</Info>

### MCP Security Model

<Warning>
**Understanding what's protected:** Not all MCP methods require authentication. Discovery methods are open so agents can find your tools, but execution requires payment verification.
</Warning>

| MCP Method | Auth Required | Why |
|------------|---------------|-----|
| `initialize` | âŒ No | Session setup |
| `tools/list` | âŒ No | Discovery - agents need to see your schemas |
| `resources/list` | âŒ No | Discovery |
| `prompts/list` | âŒ No | Discovery |
| `tools/call` | âœ… **Yes** | **Execution - costs money, runs your code** |

<Info>
**This means:**
- Anyone can call `/mcp` with `initialize` or `tools/list` to discover your tools
- Only requests with a valid Context Protocol JWT can call `tools/call`
- The middleware handles this automatically - you don't need to implement it yourself
</Info>

---

## Step 2: Test Your Tool Locally

Before deploying, ensure your server works as expected. You can use the [official MCP Inspector](https://github.com/modelcontextprotocol/inspector) or `curl` to test your tool locally.

### Using Curl

```bash
# Test your endpoint (assuming it's running on localhost:3000)
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "tools/list",
    "id": 1
  }'
```

---

## Step 3: Deploy Your Server

Your server needs to be **publicly accessible**. We support both transport methods:

| Transport | URL Format | Recommendation |
|-----------|------------|----------------|
| HTTP Streaming | `https://your-server.com/mcp` | âœ… Recommended |
| SSE (Server-Sent Events) | `https://your-server.com/sse` | Supported |

<Tip>
Deploy to any platform: Vercel, Railway, Render, AWS, or your own infrastructure. The only requirement is a publicly accessible HTTPS endpoint.
</Tip>

---

## Step 3: Register in the App

<Steps>
  <Step title="Go to /contribute">
    Navigate to the contribute page in the running Context app
  </Step>
  <Step title="Select MCP Tool">
    Choose "MCP Tool" (the default option)
  </Step>
  <Step title="Paste Your Endpoint URL">
    Enter your publicly accessible endpoint URL
  </Step>
  <Step title="Auto-Discovery">
    We'll auto-discover your skills via `listTools()`
  </Step>
</Steps>

---

## Step 4: Set a Price

Choose your fee per response:

| Price | Use Case |
|-------|----------|
| **\$0.00** | Free tools (great for adoption and visibility) |
| **\$0.01+** | Paid tools (earn revenue per response) |

<Note>
This fee is paid **once per chat turn**. The Agent can call your skills up to 100 times within that single paid turn via `callMcpSkill()`.
</Note>

<Warning>
**Security requirement depends on price:**
- **Free tools**: Security middleware is **optional** â€” your endpoint works without JWT verification
- **Paid tools**: Security middleware is **mandatory** â€” see [Secure Your Endpoint](#secure-your-endpoint)
</Warning>

---

## Step 5: Stake USDC

All tools require a minimum USDC stake, enforced on-chain.

| Tool Type | Minimum Stake |
|-----------|---------------|
| Free Tools | \$10 USDC |
| Paid Tools | \$10 USDC or 100Ã— response price (whichever is higher) |

<Info>
Stakes are **fully refundable** with a 7-day withdrawal delay. This creates accountability and enables slashing for fraud.
</Info>

---

## Step 6: You're Live! ğŸ‰

Your MCP Tool is now instantly available on the decentralized marketplace. Users can discover it via search, and AI agents can autonomously purchase and use your tool.

---

## Updating Your Tool

When you add new endpoints, modify schemas, or change your tool's functionality:

<Steps>
  <Step title="Deploy Changes">
    Push your updated code to your server/hosting
  </Step>
  
  <Step title="Refresh Skills on Context">
    1. Go to [ctxprotocol.com/developer/tools](https://www.ctxprotocol.com/developer/tools) â†’ **Developer Tools** (My Tools)
    2. Find your tool and click **"Refresh Skills"**
    3. Context re-calls `listTools()` to discover changes
  </Step>
  
  <Step title="Update Description (if needed)">
    If you've added significant new tools, update your description:
    - Use the [MCP Server Analysis Prompt](https://github.com/ctxprotocol/sdk/blob/main/docs/mcp-server-analysis-prompt.md) to generate a new description
    - Edit your tool in the Developer Tools page
  </Step>
</Steps>

<Warning>
**Don't forget to Refresh Skills!** Deploying new code doesn't automatically update the marketplace listing. You must click "Refresh Skills" for Context to re-discover your tools.
</Warning>

---

## Schema Accuracy & Dispute Resolution

<Warning>
Your `outputSchema` isn't just documentation â€” **it's a contract**.
</Warning>

Context uses automated schema validation as part of our crypto-native dispute resolution system:

1. Users can dispute tool outputs by providing their `transaction_hash` (proof of payment)
2. **Robot judge** auto-adjudicates by validating your actual output against your declared `outputSchema`
3. If schema mismatches, the dispute is resolved against you automatically
4. Repeated violations (5+ flags) lead to tool deactivation

### Example: Schema Compliance

```typescript
// âŒ BAD: Schema says number, but you return string
outputSchema: { temperature: { type: "number" } }
structuredContent: { temperature: "72" }  // GUILTY - schema mismatch!

// âœ… GOOD: Output matches schema exactly
outputSchema: { temperature: { type: "number" } }
structuredContent: { temperature: 72 }  // Valid
```

<Tip>
**Why this matters**: Unlike Web2 "star ratings" that can be gamed by bots, Context disputes require **economic proof** (you paid for the query). This protects honest developers from spam while ensuring bad actors face consequences.
</Tip>

---

## Execution Limits & Product Design

<Warning>
**Critical**: MCP tool execution on the Context platform has a **~60 second timeout**. This is intentional â€” it shapes the marketplace toward high-quality data products.
</Warning>

### Where the Timeout Comes From

The timeout is enforced by the **platform infrastructure** (and in standard MCP setups like Claude Desktop, by the LLM client itself). When your tool is called, the system waits for a response â€” if it doesn't arrive in ~60 seconds, execution fails.

When a timeout is hit, the runtime now propagates cancellation to in-flight MCP calls to avoid post-timeout "zombie" traffic. Tool authors should still return explicit failure/degraded states quickly so agents can recover gracefully.

<Note>
This isn't an MCP protocol limitation â€” SSE connections can stay open indefinitely. The timeout exists at the application layer (LLM clients, API gateways, platform infrastructure) and serves as a **quality forcing function**.
</Note>

### Why the Timeout Is Actually Good

The timeout isn't a bug â€” it's a feature that forces data brokers to build **actual products** instead of raw data access.

| Raw Access (âŒ Bad Product) | Data Broker Product (âœ… Good Product) |
|----------------------------|--------------------------------------|
| "Run any SQL on Dune" | "Smart Money Wallet Tracker" |
| "Query 4 years of NFT data" | "NFT Alpha Signals" |
| "Scan all whale wallets" | "Whale Alert Feed" |
| Timeout after 60s âŒ | Instant response âœ… |

<Note>
**The reframe**: The best data businesses don't sell raw database access. They sell curated, **pre-computed insights**. This is exactly how Bloomberg, Nansen, Arkham, and Messari work.
</Note>

### The Data Broker Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA BROKER'S JOB (offline)                      â”‚
â”‚                                                                     â”‚
â”‚  1. Run heavy queries on your data source (30 min timeout - OK)    â”‚
â”‚  2. Pre-compute valuable insights ("wallets that sold tops")       â”‚
â”‚  3. Store results in your own database                             â”‚
â”‚  4. Update daily/hourly via cron jobs                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP TOOL (instant)                               â”‚
â”‚                                                                     â”‚
â”‚  User: "What are the smart money wallets holding?"                 â”‚
â”‚  Tool: SELECT * FROM my_precomputed_smart_money LIMIT 10           â”‚
â”‚  Response: < 1 second âœ…                                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Product Tiers

<AccordionGroup>
  <Accordion title="Tier 1: Real-time Queries (< 60s)" icon="bolt">
    Perfect for MCP â€” works great today:
    - Current prices, recent trades, portfolio snapshots
    - "What's in Vitalik's wallet right now?"
    - "Get current gas prices on Ethereum"
    
    **Implementation**: Direct API calls that return quickly
  </Accordion>
  
  <Accordion title="Tier 2: Pre-computed Insights (instant)" icon="database">
    **This is the REAL product** â€” where data brokers add massive value:
    - "Smart money wallets" (pre-computed daily)
    - "Whale alerts" (pre-computed hourly)
    - "NFT trending collections" (pre-computed)
    
    **Implementation**: Heavy queries run offline via cron, results served instantly via MCP
  </Accordion>
  
  <Accordion title="What if my analysis takes longer than 60 seconds?" icon="clock">
    **If your computation can't complete in 60 seconds, you need to pre-compute it.**
    
    This is by design. The timeout forces you to build a **data product**, not raw data access:
    
    | Instead of... | Build this... |
    |---------------|---------------|
    | "Scan all whale wallets" (10 min) | "Pre-computed whale alerts" (instant) |
    | "Analyze 4 years of NFT data" (30 min) | "Daily top-mover rankings" (instant) |
    | "Run complex ML model" (5 min) | "Pre-scored predictions updated hourly" (instant) |
    
    **The pattern**: Run your heavy analysis offline (cron jobs, scheduled tasks), store the results in your own database, and serve them instantly through your MCP tool.
    
    ```typescript
    // âŒ BAD: Long-running analysis at request time
    { name: "analyze_all_wallets", returns: "timeout after 60s" }
    
    // âœ… GOOD: Pre-computed results served instantly
    { name: "get_smart_money_wallets", returns: "instant response from your DB" }
    ```
    
    This is exactly how Bloomberg, Nansen, and Arkham work â€” the value is in the **curation and pre-computation**, not raw data access.
  </Accordion>
</AccordionGroup>

### Example: Good vs Bad Tool Design

```typescript
// âŒ BAD: Raw SQL tool (timeout-prone, no moat)
{
  name: "run_sql",
  description: "Run any SQL against blockchain data"
  // This is a demo, not a product
}

// âœ… GOOD: Pre-computed insight tools
{
  name: "get_smart_money_wallets",
  description: "Get top 100 wallets that historically timed market tops",
  // Data broker pre-computes this daily, serves instantly
}

{
  name: "get_whale_holdings",
  description: "Current holdings of known whale wallets",
  // Pre-computed hourly, instant response
}
```

<Tip>
**The value you create**: Your data brokers should be selling "Nansen-as-a-service" and "Arkham-as-a-service" â€” not raw SQL access. The timeout forces this quality bar.
</Tip>

### Why This Is BETTER for the Marketplace

| Raw SQL Model | Data Broker Product Model |
|---------------|--------------------------|
| Anyone can build (no moat) | Requires expertise (defensible) |
| Competes on price (race to bottom) | Competes on quality (premium pricing) |
| Users frustrated by timeouts | Users delighted by instant results |
| Data broker adds no value | Data broker adds **massive** value |

---

## Complete Server Example

Here's a full working example of an MCP server ready for Context:

```typescript
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { SSEServerTransport } from "@modelcontextprotocol/sdk/server/sse.js";
import express from "express";
import { createContextMiddleware } from "@ctxprotocol/sdk";

const app = express();
app.use(express.json());

// Secure endpoint with Context middleware
app.use("/mcp", createContextMiddleware());

// Define tools with outputSchema
const TOOLS = [{
  name: "get_gas_price",
  description: "Get current gas prices",
  inputSchema: {
    type: "object",
    properties: {
      chainId: { type: "number", description: "EVM chain ID" },
    },
  },
  outputSchema: {
    type: "object",
    properties: {
      gasPrice: { type: "number" },
      unit: { type: "string" },
    },
    required: ["gasPrice", "unit"],
  },
}];

// Standard MCP server setup
const server = new Server(
  { name: "my-gas-tool", version: "1.0.0" },
  { capabilities: { tools: {} } }
);

server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: TOOLS,
}));

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const data = await fetchGasData(request.params.arguments.chainId);
  
  return {
    content: [{ type: "text", text: JSON.stringify(data) }],
    structuredContent: data,
  };
});

app.listen(3000, () => {
  console.log("MCP server running on port 3000");
});
```

---

## Advanced: User Actions (Handshakes)

Need your tool to execute transactions or get user signatures? Use the **Handshake Architecture**:

```typescript
import { createSignatureRequest, wrapHandshakeResponse } from "@ctxprotocol/sdk";

// In your tool handler
if (needsUserSignature) {
  return wrapHandshakeResponse(
    createSignatureRequest({
      domain: { name: "MyProtocol", version: "1", chainId: 1 },
      types: { Order: [{ name: "amount", type: "uint256" }] },
      primaryType: "Order",
      message: { amount: 1000 },
      meta: { description: "Place order", protocol: "MyProtocol" },
    })
  );
}
```

The Context app will show an approval card, the user signs, and the signature is returned to your tool.

<Card title="Handshake Architecture Guide" icon="handshake" href="/guides/handshake-architecture">
  Full guide: signatures, transactions, OAuth flows
</Card>

---

## Example Servers

Check out these complete working examples:

### TypeScript (Express + MCP SDK)

<CardGroup cols={3}>
  <Card title="Blocknative" icon="gas-pump" href="https://github.com/ctxprotocol/sdk/tree/main/examples/server/blocknative-contributor">
    Gas price API (3 tools)
  </Card>
  <Card title="Hyperliquid" icon="chart-line" href="https://github.com/ctxprotocol/sdk/tree/main/examples/server/hyperliquid-contributor">
    DeFi analytics (16+ tools, includes handshake example)
  </Card>
  <Card title="Polymarket" icon="chart-pie" href="https://github.com/ctxprotocol/sdk/tree/main/examples/server/polymarket-contributor">
    Prediction market intelligence
  </Card>
</CardGroup>

### Python (FastMCP + ctxprotocol)

<CardGroup cols={2}>
  <Card title="Hummingbot Market Intel" icon="python" href="https://github.com/ctxprotocol/sdk-python/tree/main/examples/server/hummingbot-contributor">
    Multi-exchange market data (6 tools) â€” prices, order books, funding rates, trade impact analysis
  </Card>
</CardGroup>

<Tip>
The Python example uses [FastMCP](https://gofastmcp.com) which auto-generates `outputSchema` from Pydantic models and includes `structuredContent` in responses automatically.
</Tip>
