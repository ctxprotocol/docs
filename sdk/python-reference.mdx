---
title: "Python SDK Reference"
description: "Complete API reference for ctxprotocol (Python) — installation, configuration, methods, and types"
---

## Installation

<CodeGroup>
```bash pip
pip install ctxprotocol
```

```bash poetry
poetry add ctxprotocol
```

```bash uv
uv add ctxprotocol
```
</CodeGroup>

With optional FastAPI support:

```bash
pip install ctxprotocol[fastapi]
```

### Requirements

- Python 3.10+
- httpx (async HTTP)
- pydantic (type validation)
- pyjwt[crypto] (JWT verification)

---

## Prerequisites

Before using the API, complete setup at [ctxprotocol.com](https://ctxprotocol.com):

<Steps>
  <Step title="Sign in">
    Creates your embedded wallet
  </Step>
  <Step title="Set spending cap">
    Approve USDC spending on the ContextRouter (one-time setup)
  </Step>
  <Step title="Fund wallet">
    Add USDC for tool execution fees
  </Step>
  <Step title="Generate API key">
    In Settings page
  </Step>
</Steps>

---

## Quick Start

```python
import asyncio
from ctxprotocol import ContextClient

async def main():
    async with ContextClient(api_key="sk_live_...") as client:
        answer = await client.query.run("What are the top whale movements on Base?")
        print(answer.response)

asyncio.run(main())
```

<Info>
**Want per-call pricing and spending limits?** The SDK also supports [Execute mode](#tools-execute-mode) for direct method calls inside session budgets. See [Two SDK Modes](#two-sdk-modes) below.
</Info>

---

## Two SDK Modes

The SDK offers two payment models:

| Mode | Method | Payment Model | Use Case |
|------|--------|---------------|----------|
| **Query** | `client.query.run()` | Pay-per-response | Complex questions, multi-tool synthesis, curated intelligence |
| **Execute** | `client.tools.execute()` | Per call (with spending limit) | Deterministic pipelines, raw outputs, explicit cost control |

<Info>
**You have access to both modes — pick the one that fits your use case.**

- Use **Query** (`client.query.run()`) when you want a curated answer — Context is the librarian and handles discovery/orchestration (up to 100 MCP calls per response turn). Pay-per-response (~$0.10).
- Use **Execute** (`client.tools.execute()`) when your app/agent is the librarian and you want per-call pricing with spending limits (~$0.001/call).

Most developers start with Query and add Execute later for specific pipelines that need raw data or explicit cost control. You can use both in the same application.
</Info>

### Execute Quick Start

```python
import asyncio
from ctxprotocol import ContextClient

async def main():
    async with ContextClient(api_key="sk_live_...") as client:
        tools = await client.discovery.search(
            "gas prices",
            mode="execute",
            surface="execute",
            require_execute_pricing=True,
        )
        session = await client.tools.start_session(max_spend_usd="1.00")
        method = tools[0].mcp_tools[0]
        result = await client.tools.execute(
            tool_id=tools[0].id,
            tool_name=method.name,
            args={"chainId": 1},
            session_id=session.session.session_id,
        )
        print(result.result)
        print(result.session)  # method_price, spent, remaining, max_spend, ...

asyncio.run(main())
```

<Tip>
**Full working example:** See [`examples/client/execute_client.py`](https://github.com/ctxprotocol/sdk-python/tree/main/examples/client/execute_client.py) for a complete Execute-mode client with multi-call session management and spend tracking.
</Tip>

<Note>
Mixed listings are first-class: one listing can expose methods to both modes. Methods without explicit execute pricing remain Query-only until pricing metadata is added.
</Note>

<Note>
Compatibility: payload fields like `price` and `price_per_query` are kept for backward compatibility. In Query mode, they represent listing-level **price per response turn**.
A future major release can add response-named aliases (for example, `price_per_response`) before deprecating legacy names.
</Note>

---

## Configuration

### Client Options

| Option | Type | Required | Default | Description |
|--------|------|----------|---------|-------------|
| `api_key` | `str` | Yes | — | Your Context Protocol API key |
| `base_url` | `str` | No | `https://ctxprotocol.com` | API base URL (for development) |

```python
import os
from ctxprotocol import ContextClient

# Production
client = ContextClient(api_key=os.environ["CONTEXT_API_KEY"])

# Local development
client = ContextClient(
    api_key="sk_test_...",
    base_url="http://localhost:3000",
)
```

<Note>
Always use `async with` context manager or call `await client.close()` when done to properly release resources.
</Note>

<Info>
The Python SDK automatically retries transient failures (HTTP 5xx, transport errors, and timeouts) with exponential backoff.
</Info>

---

## API Reference

### Discovery

#### `client.discovery.search(query, limit?)`

Search for tools matching a query string, with optional mode-aware filters.

**Parameters:**
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `query` | `str` | Yes | Search query |
| `limit` | `int` | No | Maximum results to return (1-50) |
| `mode` | `"query" \| "execute"` | No | Discovery mode with billing semantics |
| `surface` | `"answer" \| "execute" \| "both"` | No | Method mode filter |
| `query_eligible` | `bool` | No | Require methods marked query eligible |
| `require_execute_pricing` | `bool` | No | Require explicit method execute pricing |
| `exclude_latency_classes` | `list["instant" \| "fast" \| "slow" \| "streaming"]` | No | Exclude by latency class |
| `exclude_slow` | `bool` | No | Convenience filter for query mode |

**Returns:** `list[Tool]`

```python
tools = await client.discovery.search("ethereum gas", limit=10)

execute_tools = await client.discovery.search(
    "ethereum gas",
    mode="execute",
    surface="execute",
    require_execute_pricing=True,
)
```

---

#### `client.discovery.get_featured(limit?, ...)`

Get featured/popular tools.

**Parameters:**
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `limit` | `int` | No | Maximum results to return |
| `mode` | `"query" \| "execute"` | No | Optional discovery mode |
| `surface` | `"answer" \| "execute" \| "both"` | No | Optional method mode filter |
| `query_eligible` | `bool` | No | Optional query-safe filter |
| `require_execute_pricing` | `bool` | No | Optional execute-price filter |

**Returns:** `list[Tool]`

```python
featured = await client.discovery.get_featured(limit=5)
featured_execute = await client.discovery.get_featured(
    limit=5,
    mode="execute",
    require_execute_pricing=True,
)
```

---

### Tools (Execute Mode)

#### `client.tools.execute(tool_id, tool_name, args?)`

Execute a single tool method. Execute calls can run inside a session budget (`max_spend_usd`) with automatic payment after delivery.

**Parameters:**
| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `tool_id` | `str` | Yes | UUID of the tool |
| `tool_name` | `str` | Yes | Name of the method to call |
| `args` | `dict` | No | Arguments matching the tool's `inputSchema` |
| `idempotency_key` | `str` | No | Optional idempotency key (UUID recommended) |
| `mode` | `"execute"` | No | Explicit mode label (defaults to `"execute"`) |
| `session_id` | `str` | No | Execute session ID to accrue spend against |
| `max_spend_usd` | `str` | No | Optional inline session budget (if no `session_id`) |
| `close_session` | `bool` | No | Request session closure after this call settles |

**Returns:** `ExecutionResult`

```python
session = await client.tools.start_session(max_spend_usd="2.50")

result = await client.tools.execute(
    tool_id="uuid-of-tool",
    tool_name="get_gas_prices",
    args={"chainId": 1},
    idempotency_key="2bb4bdcb-8609-43f6-af13-75279186de70",
    session_id=session.session.session_id,
)
print(result.method.execute_price_usd)  # explicit method price
print(result.session)  # method_price, spent, remaining, max_spend, ...
```

#### `client.tools.start_session(max_spend_usd)`

Start an execute session budget envelope.

```python
started = await client.tools.start_session(max_spend_usd="5.00")
print(started.session.session_id)
print(started.session.max_spend)
```

#### `client.tools.get_session(session_id)`

Fetch current execute session status/spend.

```python
status = await client.tools.get_session("sess_123")
print(status.session.status)  # open | closed | expired
print(status.session.spent)
```

#### `client.tools.close_session(session_id)`

Close an execute session and trigger final flush behavior.

```python
closed = await client.tools.close_session("sess_123")
print(closed.session.status)  # closed
```

---

### Query (Pay-Per-Response)

<Info>
The Query API is Context's **response marketplace** — instead of buying raw API calls, you're buying curated intelligence. Ask a question, pay once, and get an AI-synthesized answer backed by multi-tool data aggregation, error recovery, and completeness checks.
</Info>

#### `client.query.run(query, tools?, model_id?, include_data?, include_data_url?, idempotency_key?)`

Run an agentic query. The server discovers query-eligible tools, executes the full pipeline (up to 100 MCP calls per response turn as a runtime safety cap), applies model-aware mediator/data budgeting, and returns an AI-synthesized answer. Query billing is pay-per-response with automatic payment after delivery.

**Parameters:**
| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `query` | `str` | Yes | Natural-language question |
| `tools` | `list[str]` | No | Tool IDs to use (auto-discover if omitted) |
| `model_id` | `str` | No | Model ID to use for planning/synthesis (e.g. `kimi-model-thinking`, `glm-model`) |
| `include_data` | `bool` | No | Include execution data inline in the response |
| `include_data_url` | `bool` | No | Persist execution data to blob and return a URL |
| `idempotency_key` | `str` | No | Optional idempotency key (UUID recommended) |

**Returns:** `QueryResult`

```python
answer = await client.query.run("What are the top whale movements on Base?")
print(answer.response)      # AI-synthesized text
print(answer.tools_used)    # [QueryToolUsage(id, name, skill_calls)]
print(answer.cost)          # QueryCost(model_cost_usd, tool_cost_usd, total_cost_usd)
```

```python
answer = await client.query.run(
    query="Analyze whale activity on Base",
    model_id="glm-model",
    include_data=True,
    include_data_url=True,
    idempotency_key="6e7f1389-f72f-41d9-bf26-0608a4d8be87",
)
```

<Note>
`model_id` lets headless users choose the orchestration/synthesis model explicitly. If omitted, the API uses its default model.

Current platform IDs: `kimi-model-thinking`, `glm-model`, `gemini-flash-model`, `claude-sonnet-model`, `claude-opus-model`.
</Note>

#### `client.query.stream(query, tools?, model_id?, include_data?, include_data_url?, idempotency_key?)`

Same as `run()` but streams events in real-time via SSE.

**Returns:** `AsyncGenerator` of stream events

```python
async for event in client.query.stream("What are the top whale movements?"):
    if event.type == "tool-status":
        print(f"Tool {event.tool.name}: {event.status}")
    elif event.type == "text-delta":
        print(event.delta, end="")
    elif event.type == "done":
        print(f"\nTotal cost: {event.result.cost.total_cost_usd}")
```

<Note>
Use the same `idempotency_key` when retrying the same logical request after network or timeout errors.
</Note>

---

## Types

### Import Types

```python
from ctxprotocol import (
    # Auth utilities for tool contributors
    verify_context_request,
    is_protected_mcp_method,
    is_open_mcp_method,

    # Client types
    ContextClientOptions,
    Tool,
    McpTool,
    ExecuteOptions,
    ExecutionResult,
    ContextErrorCode,

    # Auth types (for MCP server contributors)
    VerifyRequestOptions,

    # Context types (for MCP server contributors receiving injected data)
    ContextRequirementType,
    HyperliquidContext,
    PolymarketContext,
    WalletContext,
    UserContext,
)
```

---

### Tool

```python
class Tool(BaseModel):
    id: str
    name: str
    description: str
    price: str  # listing-level response price metadata (legacy field name)
    category: str | None
    is_verified: bool | None
    mcp_tools: list[McpTool] | None
```

---

### McpTool

```python
class McpTool(BaseModel):
    name: str
    description: str
    input_schema: dict[str, Any] | None  # JSON Schema for arguments
    output_schema: dict[str, Any] | None  # JSON Schema for response
    meta: dict[str, Any] | None  # alias: "_meta" (mode/eligibility/pricing/context)
    execute_eligible: bool | None
    execute_price_usd: str | None
```

<Info>
For argument guidance, use standard JSON Schema fields directly inside `inputSchema` properties. Put fallback values in `default` and sample invocations in `examples`. Do not rely on custom `_meta.inputExamples`.
</Info>

```python
TOOLS = [{
    "name": "get_price_history",
    "inputSchema": {
        "type": "object",
        "properties": {
            "symbol": {"type": "string", "default": "BTC", "examples": ["BTC", "ETH", "SOL"]},
            "interval": {"type": "string", "enum": ["1h", "4h", "1d"], "default": "1h", "examples": ["1h", "4h"]},
            "limit": {"type": "number", "default": 100, "examples": [50, 100, 200]},
        },
        "required": [],
    },
}]
```

---

### ExecutionResult (Execute Mode)

```python
class ExecutionResult(BaseModel):
    mode: Literal["execute"]
    result: Any
    tool: ToolInfo  # { id: str, name: str }
    method: ExecuteMethodInfo  # { name: str, execute_price_usd: str }
    session: ExecuteSessionSpend
    duration_ms: int
```

### ExecuteSessionSpend

```python
class ExecuteSessionSpend(BaseModel):
    mode: Literal["execute"] = "execute"
    session_id: str | None
    method_price: str
    spent: str
    remaining: str | None
    max_spend: str | None
    status: Literal["open", "closed", "expired"] | None
    expires_at: str | None
    close_requested: bool | None
    pending_accrued_count: int | None
    pending_accrued_usd: str | None
```

---

### QueryResult (Pay-Per-Response)

```python
class QueryResult(BaseModel):
    response: str                        # AI-synthesized answer
    tools_used: list[QueryToolUsage]     # [{ id, name, skill_calls }]
    cost: QueryCost                      # { model_cost_usd, tool_cost_usd, total_cost_usd }
    duration_ms: int
    data: Any | None                     # Optional execution data (include_data=True)
    data_url: str | None                 # Optional blob URL (include_data_url=True)
```

---

### Context Requirement Types

For MCP server contributors building tools that need user context:

<Info>
**Why Context Injection Matters:**

- **No Auth Required**: Public blockchain/user data is fetched by the platform
- **Security**: Your MCP server never handles private keys
- **Simplicity**: You receive structured, type-safe data
</Info>

```python
from ctxprotocol import CONTEXT_REQUIREMENTS_KEY

# Context types supported by the marketplace
ContextRequirementType = Literal["polymarket", "hyperliquid", "wallet"]

# Usage: Declare context requirements in _meta at the tool level
TOOLS = [{
    "name": "analyze_my_positions",
    "description": "Analyze your positions with personalized insights",
    "_meta": {
        "contextRequirements": ["hyperliquid"],
        "rateLimit": {
            "maxRequestsPerMinute": 30,
            "cooldownMs": 2000,
            "maxConcurrency": 1,
            "supportsBulk": True,
            "recommendedBatchTools": ["get_portfolio_snapshot"],
            "notes": "Hobby tier: prefer snapshot endpoints over loops.",
        },
    },
    "inputSchema": {
        "type": "object",
        "properties": {
            "portfolio": {
                "type": "object",
                "description": "Portfolio context (injected by platform)",
            },
        },
        "required": ["portfolio"],
    },
}]
```

<Info>
Python reference implementation: [Hummingbot contributor server](https://github.com/ctxprotocol/sdk-python/tree/main/examples/server/hummingbot-contributor).
</Info>

<Info>
For practical guidance on these pacing hints, see [Tool Metadata](/guides/tool-metadata#rate-limit-hints).
</Info>

---

### Injected Context Types

#### HyperliquidContext

```python
class HyperliquidContext(BaseModel):
    wallet_address: str
    perp_positions: list[HyperliquidPerpPosition]
    spot_balances: list[HyperliquidSpotBalance]
    open_orders: list[HyperliquidOrder]
    account_summary: HyperliquidAccountSummary
    fetched_at: str
```

#### PolymarketContext

```python
class PolymarketContext(BaseModel):
    wallet_address: str
    positions: list[PolymarketPosition]
    open_orders: list[PolymarketOrder]
    total_value: float | None
    fetched_at: str
```

#### WalletContext

```python
class WalletContext(BaseModel):
    address: str
    chain_id: int
    native_balance: str | None
```

---

## Error Handling

The SDK raises `ContextError` with specific error codes:

```python
from ctxprotocol import ContextClient, ContextError

try:
    result = await client.tools.execute(...)
except ContextError as e:
    match e.code:
        case "no_wallet":
            # User needs to set up wallet
            print(f"Setup required: {e.help_url}")
        case "insufficient_allowance":
            # User needs to set a spending cap
            print(f"Set spending cap: {e.help_url}")
        case "payment_failed":
            # Insufficient USDC balance
            pass
        case "execution_failed":
            # Tool execution error
            pass
```

### Error Codes

| Code | Description | Handling |
|------|-------------|----------|
| `unauthorized` | Invalid API key | Check configuration |
| `no_wallet` | Wallet not set up | Direct user to `help_url` |
| `insufficient_allowance` | Spending cap not set | Direct user to `help_url` |
| `payment_failed` | USDC payment failed | Check balance |
| `execution_failed` | Tool error | Retry with different args |

---

## Securing Your Tool (MCP Contributors)

If you're building an MCP server, verify incoming requests using `ctxprotocol`.

<Info>
**Free vs Paid Security Requirements:**

| Tool Type | Security Middleware | Rationale |
|-----------|---------------------|-----------|
| **Free Tools ($0.00)** | **Optional** | Great for distribution and adoption |
| **Paid Tools ($0.01+)** | **Mandatory** | We cannot route payments to insecure endpoints |
</Info>

### Option 1: FastMCP (Recommended)

[FastMCP](https://gofastmcp.com) is the fastest way to build MCP servers. Use `ctxprotocol` middleware:

```python
from fastmcp import FastMCP
from fastmcp.server.middleware import Middleware, MiddlewareContext
from fastmcp.server.dependencies import get_http_headers
from fastmcp.exceptions import ToolError
from ctxprotocol import verify_context_request, ContextError

mcp = FastMCP("my-tool")

class ContextProtocolAuth(Middleware):
    """Verify Context Protocol JWT on tool calls only."""
    
    async def on_call_tool(self, context: MiddlewareContext, call_next):
        headers = get_http_headers()
        try:
            await verify_context_request(
                authorization_header=headers.get("authorization", "")
            )
        except ContextError as e:
            raise ToolError(f"Unauthorized: {e.message}")
        return await call_next(context)

mcp.add_middleware(ContextProtocolAuth())

@mcp.tool
def get_data(query: str) -> dict:
    return {"result": "..."}

if __name__ == "__main__":
    mcp.run(transport="http", port=3000)
```

<Tip>
FastMCP auto-generates `outputSchema` from Pydantic return types and includes `structuredContent` in responses - both required by Context Protocol.
</Tip>

### Option 2: Raw FastAPI

For more control, use FastAPI with our middleware:

```python
from fastapi import FastAPI, Request, Depends, HTTPException
from ctxprotocol import create_context_middleware, ContextError

app = FastAPI()
verify_context = create_context_middleware(audience="https://your-tool.com/mcp")

@app.post("/mcp")
async def handle_mcp(request: Request, context: dict = Depends(verify_context)):
    # context contains verified JWT payload (on protected methods)
    # None for open methods like tools/list
    body = await request.json()
    # Handle MCP request...
```

### Manual Verification

For more control, use the lower-level utilities:

```python
from ctxprotocol import verify_context_request, is_protected_mcp_method, ContextError

# Check if a method requires auth
if is_protected_mcp_method(body["method"]):
    try:
        payload = await verify_context_request(
            authorization_header=request.headers.get("authorization"),
            audience="https://your-tool.com/mcp",  # optional
        )
        # payload contains verified JWT claims
    except ContextError:
        raise HTTPException(status_code=401, detail="Unauthorized")
```

### Verification Options

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `authorization_header` | `str` | Yes | Full Authorization header (e.g., `"Bearer eyJ..."`) |
| `audience` | `str` | No | Expected audience claim for stricter validation |

### MCP Security Model

<Warning>
**Critical for tool contributors:** Not all MCP methods require authentication. The middleware **selectively** protects only execution methods.
</Warning>

| MCP Method | Auth Required | Why |
|------------|---------------|-----|
| `initialize` | ❌ No | Session setup |
| `tools/list` | ❌ No | Discovery - agents need to see your schemas |
| `resources/list` | ❌ No | Discovery |
| `prompts/list` | ❌ No | Discovery |
| `tools/call` | ✅ **Yes** | **Execution - costs money, runs your code** |

<Info>
**What this means in practice:**
- ✅ `https://your-mcp.com/mcp` + `initialize` → Works without auth
- ✅ `https://your-mcp.com/mcp` + `tools/list` → Works without auth  
- ❌ `https://your-mcp.com/mcp` + `tools/call` → **Requires Context Protocol JWT**

This matches standard API patterns (OpenAPI schemas are public, GraphQL introspection is open).
</Info>

---

## Payment Flow

Context supports two settlement timings:

1. **Query mode (`client.query.*`)** uses deferred settlement after the response is delivered
2. **Execute mode (`client.tools.execute`)** accrues per-call method spend into execute sessions with automatic batch payment
3. In both modes, spending caps are enforced via ContextRouter allowance checks
4. **90%** goes to the tool developer, **10%** goes to the protocol

---

## Links

- [Context Protocol](https://ctxprotocol.com) — Main website
- [PyPI Package](https://pypi.org/project/ctxprotocol/)
- [GitHub (Python SDK)](https://github.com/ctxprotocol/sdk-python)
- [TypeScript SDK](/sdk/reference) — For Node.js

